{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Tracing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far in this module, we've taken a look at the traceable decorator, and how we can use it to set up tracing.\n",
    "\n",
    "In this lesson, we're going to look at alternative ways in which we can set up tracing, and when you should think about using these different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain and LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are using LangChain or LangGraph, all we need to do to set up tracing is to set a few environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\"  # If you don't set this, traces will go to the Default project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry too much about our graph implementation here, you can learn more about LangGraph through our LangGraph Academy course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import operator\n",
    "from langchain.schema import Document\n",
    "from langchain_core.messages import HumanMessage, AnyMessage, get_buffer_string\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from utils import get_vector_db_retriever, RAG_PROMPT\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "retriever = get_vector_db_retriever()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define Graph state\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    messages: Annotated[List[AnyMessage], operator.add]\n",
    "    documents: List[Document]\n",
    "\n",
    "# Define Nodes\n",
    "def retrieve_documents(state: GraphState):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(f\"{get_buffer_string(messages)} {question}\")\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "def generate_response(state: GraphState):\n",
    "    question = state[\"question\"]\n",
    "    messages = state[\"messages\"]\n",
    "    documents = state[\"documents\"]\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    \n",
    "    rag_prompt_formatted = RAG_PROMPT.format(context=formatted_docs, conversation=messages, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    return {\"documents\": documents, \"messages\": [HumanMessage(question), generation]}\n",
    "\n",
    "# Define Graph\n",
    "graph_builder = StateGraph(GraphState)\n",
    "graph_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "graph_builder.add_node(\"generate_response\", generate_response)\n",
    "graph_builder.add_edge(START, \"retrieve_documents\")\n",
    "graph_builder.add_edge(\"retrieve_documents\", \"generate_response\")\n",
    "graph_builder.add_edge(\"generate_response\", END)\n",
    "\n",
    "simple_rag_graph = graph_builder.compile()\n",
    "display(Image(simple_rag_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're setting up a simple graph in LangGraph. If you want to learn more about LangGraph, I would highly recommend taking a look at our LangGraph Academy course.\n",
    "\n",
    "You can also pass in metadata or other fields through an optional config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"How do I set up tracing if I'm using LangChain?\",\n",
       " 'messages': [HumanMessage(content=\"How do I set up tracing if I'm using LangChain?\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='To set up tracing with LangChain, first install the LangGraph library and the OpenAI integration for your chosen programming language. Then, configure your environment by setting the necessary environment variables, including `LANGSMITH_TRACING` and your API keys. Finally, you can log traces as normal, and LangSmith will infer the proper tracing configuration.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 673, 'total_tokens': 743, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BQRRCwSGVfr8AlQZAPR70588R5hTg', 'finish_reason': 'stop', 'logprobs': None}, id='run-214f48ad-2fea-421b-840f-e9972555344f-0', usage_metadata={'input_tokens': 673, 'output_tokens': 70, 'total_tokens': 743, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'documents': [Document(metadata={'id': '90fbcdf1-0398-4bab-8160-1b59e5480ccb', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph'}, page_content=\"3. Log a trace\\u200b\\nOnce you've set up your environment, you can call LangChain runnables as normal.\\nLangSmith will infer the proper tracing config:\"),\n",
       "  Document(metadata={'id': 'c0155d8a-d296-4748-b270-ab248ba70c87', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_langchain_with_otel', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_langchain_with_otel'}, page_content='Setting up Distributed Tracing with LangChain\\u200b\\nTo enable distributed tracing across multiple services:'),\n",
       "  Document(metadata={'id': '7851f29a-cbea-4ce5-9b2e-e27f9a007526', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langchain', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langchain'}, page_content='If you prefer a video tutorial, check out the Alternative Ways to Trace video from the Introduction to LangSmith Course.Was this page helpful?You can leave detailed feedback on GitHub.PreviousTrace generator functionsNextTrace with LangGraph (Python and JS/TS)InstallationQuick start1. Configure your environment2. Log a trace3. View your traceTrace selectivelyLog to a specific projectStaticallyDynamicallyAdd metadata and tags to tracesCustomize run nameCustomize run IDAccess run (span) ID for LangChain invocationsEnsure all traces are submitted before exitingTrace without setting environment variablesDistributed tracing with LangChain (Python)Interoperability between LangChain (Python) and LangSmith SDKInteroperability between LangChain.JS and LangSmith SDKTracing LangChain objects inside traceable (JS only)Tracing LangChain child runs via traceable / RunTree API (JS only)CommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.'),\n",
       "  Document(metadata={'id': '3504a0de-e59d-4824-9fd8-b4bdf6d5d15e', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph'}, page_content='This guide will walk through a basic example. For more detailed information on configuration, see the Trace With LangChain guide.\\n1. Installation\\u200b\\nInstall the LangGraph library and the OpenAI integration for Python and JS (we use the OpenAI integration for the code snippets below).\\nFor a full list of packages available, see the LangChain Python docs and LangChain JS docs.\\npipyarnnpmpnpmpip install langchain_openai langgraphyarn add @langchain/openai @langchain/langgraphnpm install @langchain/openai @langchain/langgraphpnpm add @langchain/openai @langchain/langgraph\\n2. Configure your environment\\u200b\\nPythonTypeScriptexport LANGSMITH_TRACING=trueexport LANGSMITH_API_KEY=<your-api-key># This example uses OpenAI, but you can use any LLM provider of choiceexport OPENAI_API_KEY=<your-openai-api-key>export LANGSMITH_TRACING=trueexport LANGSMITH_API_KEY=<your-api-key># This example uses OpenAI, but you can use any LLM provider of choiceexport OPENAI_API_KEY=<your-openai-api-key>infoIf you are using LangChain.js with LangSmith and are not in a serverless environment, we also recommend setting the following explicitly to reduce latency:\\nexport LANGCHAIN_CALLBACKS_BACKGROUND=true\\nIf you are in a serverless environment, we recommend setting the reverse to allow tracing to finish before your function ends:\\nexport LANGCHAIN_CALLBACKS_BACKGROUND=false\\nSee this LangChain.js guide for more information.')]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I set up tracing if I'm using LangChain?\"\n",
    "simple_rag_graph.invoke({\"question\": question}, config={\"metadata\": {\"foo\": \"bar\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a look in LangSmith!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing Context Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, you can use the trace context manager to log traces to LangSmith. This is useful in situations where:\n",
    "\n",
    "You want to log traces for a specific block of code.\n",
    "You want control over the inputs, outputs, and other attributes of the trace.\n",
    "It is not feasible to use a decorator or wrapper.\n",
    "Any or all of the above.\n",
    "The context manager integrates seamlessly with the traceable decorator and wrap_openai wrapper, so you can use them together in the same application.\n",
    "\n",
    "You still need to set your `LANGSMITH_API_KEY` and `LANGSMITH_TRACING`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable, trace\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable\n",
    "def retrieve_documents(question: str):\n",
    "    documents = retriever.invoke(question)\n",
    "    return documents\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_openai` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "# TODO: Remove traceable, and use with trace()\n",
    "# @traceable\n",
    "def generate_response(question: str, documents):\n",
    "    # NOTE: Our documents came in as a list of objects, but we just want to log a string\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    # TODO: Use with trace()\n",
    "    with trace(\n",
    "        name=\"Generate Response\",\n",
    "        run_type=\"chain\", \n",
    "        inputs={\"question\": question, \"formatted_docs\": formatted_docs},\n",
    "        metadata={\"foo\": \"bar\"},\n",
    "    ) as ls_trace:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": RAG_SYSTEM_PROMPT\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "            }\n",
    "        ]\n",
    "        response = call_openai(messages)\n",
    "        # TODO: End your trace and write outputs to LangSmith\n",
    "        ls_trace.end(outputs={\"output\": response})\n",
    "        return response\n",
    "\n",
    "\"\"\"\n",
    "call_openai\n",
    "- Returns the chat completion output from OpenAI\n",
    "\"\"\"\n",
    "@traceable\n",
    "def call_openai(\n",
    "    messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.0\n",
    ") -> str:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To trace with the tracing context in Python, you should use the `with tracing_context:` context manager. This allows you to log traces for specific blocks of code while providing control over inputs, outputs, and other attributes. This method is recommended for enabling or disabling tracing without needing to set environment variables.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I trace with tracing context?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrap_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrap_openai/wrapOpenAI methods in Python/TypeScript allow you to wrap your OpenAI client in order to automatically log traces -- no decorator or function wrapping required! The wrapper works seamlessly with the @traceable decorator or traceable function and you can use both in the same application.\n",
    "\n",
    "You still need to set your `LANGSMITH_API_KEY` and `LANGSMITH_TRACING`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import wrap_openai\n",
    "from langsmith.wrappers import wrap_openai\n",
    "import openai\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Wrap the OpenAI Client\n",
    "openai_client = wrap_openai(openai.Client())\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    # TODO: We don't need to use @traceable on a nested function call anymore,\n",
    "    # wrap_openai takes care of this for us\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag_with_wrap_openai(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I trace with wrap_openai?\"\n",
    "ai_answer = langsmith_rag_with_wrap_openai(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapped OpenAI client accepts all the same langsmith_extra parameters as @traceable decorated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What color is the sky?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    langsmith_extra={\"metadata\": {\"foo\": \"bar\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## [Advanced] RunTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another, more explicit way to log traces to LangSmith is via the RunTree API. This API allows you more control over your tracing - you can manually create runs and children runs to assemble your trace. You still need to set your `LANGSMITH_API_KEY`, but `LANGSMITH_TRACING` is not necessary for this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# I have my env variables defined in a .env file\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and set `LANGSMITH_TRACING` to false, as we are using RunTree to manually create runs in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"false\"\n",
    "\n",
    "from langsmith import utils\n",
    "utils.tracing_is_enabled() # This should return false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have rewritten our RAG application, except this time we pass a RunTree argument through our function calls, and create child runs at each layer. This gives our RunTree the same hierarchy that we were automatically able to establish with @traceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import RunTree\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "def retrieve_documents(parent_run: RunTree, question: str):\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Retrieve Documents\",\n",
    "        run_type=\"retriever\",\n",
    "        inputs={\"question\": question},\n",
    "    )\n",
    "    documents = retriever.invoke(question)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"documents\": documents})\n",
    "    child_run.post()\n",
    "    return documents\n",
    "\n",
    "def generate_response(parent_run: RunTree, question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    rag_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    \"\"\"\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Generate Response\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question, \"documents\": documents},\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": rag_system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    openai_response = call_openai(child_run, messages)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"openai_response\": openai_response})\n",
    "    child_run.post()\n",
    "    return openai_response\n",
    "\n",
    "def call_openai(\n",
    "    parent_run: RunTree, messages: List[dict], model: str = \"gpt-4o-mini\", temperature: float = 0.0\n",
    ") -> str:\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"OpenAI Call\",\n",
    "        run_type=\"llm\",\n",
    "        inputs={\"messages\": messages},\n",
    "    )\n",
    "    openai_response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"openai_response\": openai_response})\n",
    "    child_run.post()\n",
    "    return openai_response\n",
    "\n",
    "def langsmith_rag(question: str):\n",
    "    # Create a root RunTree\n",
    "    root_run_tree = RunTree(\n",
    "        name=\"Chat Pipeline\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question}\n",
    "    )\n",
    "\n",
    "    # Pass our RunTree into the nested function calls\n",
    "    documents = retrieve_documents(root_run_tree, question)\n",
    "    response = generate_response(root_run_tree, question, documents)\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    # Post our final output\n",
    "    root_run_tree.end(outputs={\"generation\": output})\n",
    "    root_run_tree.post()\n",
    "    return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I trace with RunTree?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
